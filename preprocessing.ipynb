{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be284456",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8ea76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataclasses import dataclass\n",
    "from typing import Iterator, Optional\n",
    "import random\n",
    "from datetime import datetime\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941e9d8",
   "metadata": {},
   "source": [
    "### load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d0d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('consumption_temp.csv')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfec95cb",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79f4bd",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fe9049",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, city, starting_date):\n",
    "    \"\"\"Basic preprocessing: filter by city, convert time to datetime, set index, sort, filter by starting date.\"\"\"\n",
    "    df = df.copy()\n",
    "    df[\"datetime\"] = pd.to_datetime(df[\"time\"])\n",
    "\n",
    "    city_norm = city.strip().lower()\n",
    "    df_city = df[df[\"location\"].astype(str).str.strip().str.lower() == city_norm].copy()\n",
    "\n",
    "    df_city = df_city.set_index(\"datetime\").sort_index()\n",
    "    df_city = df_city.loc[pd.Timestamp(starting_date):]\n",
    "\n",
    "    return df_city\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdb134",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = preprocess_data(df, city='bergen', starting_date='2022-08-01') \n",
    "location_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcfa1ca",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e497649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_features(\n",
    "    df: pd.DataFrame,\n",
    "    *,\n",
    "    target_col: str = \"consumption\",\n",
    "    temp_col: str | None = \"temperature\",\n",
    "    delay_days: int = 5,\n",
    "    drop_cols: list[str] | None = None,\n",
    "    add_cyclical: bool = True,\n",
    "    add_consumption_lags: bool = True,\n",
    "    add_consumption_rollings: bool = True,\n",
    "    cons_lags: tuple[int, ...] = (120, 168),\n",
    "    cons_rolling_windows: tuple[int, ...] = (168, 336),\n",
    "    temp_lags: tuple[int, ...] = (24, 168),\n",
    "    temp_rolling_windows: tuple[int, ...] = (24, 168),\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Feature engineering for hourly day-ahead. 5 day data delay on consumption.\n",
    "\n",
    "    Returns a NEW dataframe.\n",
    "    \"\"\"\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"DataFrame index must be a DatetimeIndex.\")\n",
    "\n",
    "    out = df.copy()\n",
    "    delay_h = int(delay_days * 24)\n",
    "\n",
    "    # Basic calendar features (used for cyclical encodings)\n",
    "    hour = out.index.hour\n",
    "    dow = out.index.dayofweek\n",
    "    month = out.index.month\n",
    "    woy = out.index.isocalendar().week.astype(int)\n",
    "\n",
    "    out[\"is_weekend\"] = (dow >= 5).astype(int)\n",
    "    out[\"hour\"] = hour\n",
    "    out[\"day_of_week\"] = dow\n",
    "    out[\"month\"] = month\n",
    "    out[\"week_of_year\"] = woy\n",
    "\n",
    "    # Cyclical encodings\n",
    "    if add_cyclical:\n",
    "        out[\"hour_sin\"] = np.sin(2 * np.pi * hour / 24.0)\n",
    "        out[\"hour_cos\"] = np.cos(2 * np.pi * hour / 24.0)\n",
    "\n",
    "        out[\"dow_sin\"] = np.sin(2 * np.pi * dow / 7.0)\n",
    "        out[\"dow_cos\"] = np.cos(2 * np.pi * dow / 7.0)\n",
    "\n",
    "        out[\"month_sin\"] = np.sin(2 * np.pi * (month - 1) / 12.0)\n",
    "        out[\"month_cos\"] = np.cos(2 * np.pi * (month - 1) / 12.0)\n",
    "\n",
    "        out[\"woy_sin\"] = np.sin(2 * np.pi * (woy - 1) / 52.0)\n",
    "        out[\"woy_cos\"] = np.cos(2 * np.pi * (woy - 1) / 52.0)\n",
    "\n",
    "    # Temperature features \n",
    "    out[temp_col] = out[temp_col].astype(float)\n",
    "\n",
    "    for k in temp_lags:\n",
    "        out[f\"temp_lag_{k}\"] = out[temp_col].shift(k)\n",
    "\n",
    "    shifted_temp = out[temp_col].shift(1)\n",
    "    for w in temp_rolling_windows:\n",
    "        out[f\"temp_roll_mean_{w}\"] = shifted_temp.rolling(window=w, min_periods=w).mean()\n",
    "        out[f\"temp_roll_std_{w}\"]  = shifted_temp.rolling(window=w, min_periods=w).std()\n",
    "\n",
    "    out[\"heating_degree_18\"] = np.maximum(0.0, 18.0 - out[temp_col])\n",
    "\n",
    "    # Consumption lag features, available with 5 day delay\n",
    "    if add_consumption_lags:\n",
    "        for k in cons_lags:\n",
    "            out[f\"lag_{k}\"] = out[target_col].shift(k)\n",
    "\n",
    "    # Consumption rolling stats\n",
    "    if add_consumption_rollings:\n",
    "        avail = out[target_col].shift(delay_h)\n",
    "        for w in cons_rolling_windows:\n",
    "            out[f\"avail_roll_mean_{w}\"] = avail.rolling(window=w, min_periods=w).mean()\n",
    "            out[f\"avail_roll_std_{w}\"]  = avail.rolling(window=w, min_periods=w).std()\n",
    "\n",
    "    # Drop redundant raw time columns\n",
    "    out = out.drop(columns=[c for c in [\"hour\", \"day_of_week\", \"month\", \"week_of_year\"] if c in out.columns])\n",
    "\n",
    "    # Optional drops\n",
    "    if drop_cols:\n",
    "        out = out.drop(columns=[c for c in drop_cols if c in out.columns])\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595b7658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering cell\n",
    "data = location_df.copy()\n",
    "\n",
    "data = add_time_features(\n",
    "    data,\n",
    "    target_col=\"consumption\",\n",
    "    temp_col=\"temperature\",\n",
    "    delay_days=5,\n",
    "    drop_cols=[\"time\", \"location\", \"datetime\"],\n",
    "    cons_lags=(120, 168), # safe under 5-day delay data constraint\n",
    "    cons_rolling_windows=(168, 336),\n",
    "    temp_lags=(24, 168),\n",
    "    temp_rolling_windows=(24, 168),\n",
    ")\n",
    "\n",
    "# drop NaNs introduced by lag/rolling features\n",
    "data = data.dropna()\n",
    "\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244979e",
   "metadata": {},
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb61142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SlidingSplit:\n",
    "    forecast_date: pd.Timestamp\n",
    "    # boundaries (useful for logging/debug)\n",
    "    train_start: pd.Timestamp\n",
    "    train_end: pd.Timestamp\n",
    "    val_start: pd.Timestamp\n",
    "    val_end: pd.Timestamp\n",
    "    test_start: pd.Timestamp\n",
    "    test_end: pd.Timestamp\n",
    "    # data\n",
    "    X_train: pd.DataFrame\n",
    "    y_train: pd.Series\n",
    "    X_val: pd.DataFrame\n",
    "    y_val: pd.Series\n",
    "    X_test: pd.DataFrame\n",
    "    y_test: pd.Series\n",
    "\n",
    "\n",
    "def iter_sliding_day_ahead_splits(\n",
    "    df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    feature_cols: list[str],\n",
    "    *,\n",
    "    last_incomplete_day: str = \"2023-04-02\",\n",
    "    last_complete_day: str = \"2023-04-01\",\n",
    "    test_days: int = 14,\n",
    "    history_days: int = 180, # train+val horizon (sliding)\n",
    "    val_days: int = 14, # inside the 180d window\n",
    ") -> Iterator[SlidingSplit]:\n",
    "    \"\"\"\n",
    "    Sliding time-window splits for day-ahead forecasting.\n",
    "\n",
    "    - Last day dropped for simplicity\n",
    "    - Uses the last complete day as `last_complete_day`.\n",
    "    - Test window = last `test_days` days ending `last_complete_day` (inclusive).\n",
    "    - For each test day D:\n",
    "        * history window = [D - history_days, D)\n",
    "        * validation = last `val_days` of history\n",
    "        * training = the rest of history before validation\n",
    "        * test = [D, D+1) one day ahead\n",
    "    \"\"\"\n",
    "\n",
    "    if not isinstance(df.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"df.index must be a DatetimeIndex\")\n",
    "\n",
    "    df = df.sort_index()\n",
    "\n",
    "    tz = df.index.tz\n",
    "    def _ts(s: str) -> pd.Timestamp:\n",
    "        t = pd.Timestamp(s)\n",
    "        if tz is not None:\n",
    "            t = t.tz_localize(tz) if t.tzinfo is None else t.tz_convert(tz)\n",
    "        return t.normalize()\n",
    "\n",
    "    last_incomplete = _ts(last_incomplete_day)\n",
    "    last_complete = _ts(last_complete_day)\n",
    "\n",
    "    # 1) Exclude incomplete last day (drop everything from 2023-04-02 00:00 and onward)\n",
    "    df = df.loc[: last_incomplete - pd.Timedelta(seconds=1)]\n",
    "\n",
    "    # 2) Ensure we donâ€™t accidentally include anything beyond last_complete day\n",
    "    df = df.loc[: last_complete + pd.Timedelta(days=1) - pd.Timedelta(seconds=1)]\n",
    "\n",
    "    # 3) Define test window days (inclusive)\n",
    "    test_start_day = last_complete - pd.Timedelta(days=test_days - 1)\n",
    "    test_days_range = pd.date_range(test_start_day, last_complete, freq=\"D\", tz=tz)\n",
    "\n",
    "    for D in test_days_range:\n",
    "        test_start = D\n",
    "        test_end = D + pd.Timedelta(days=1)\n",
    "\n",
    "        # history window immediately before D\n",
    "        hist_end = test_start\n",
    "        hist_start = hist_end - pd.Timedelta(days=history_days)\n",
    "\n",
    "        # clip to available data\n",
    "        hist_start = max(hist_start, df.index.min().normalize())\n",
    "\n",
    "        # validation = last val_days inside history\n",
    "        val_end = hist_end\n",
    "        val_start = val_end - pd.Timedelta(days=val_days)\n",
    "        val_start = max(val_start, hist_start)\n",
    "\n",
    "        train_start = hist_start\n",
    "        train_end = val_start  # exclusive\n",
    "\n",
    "        # Slice hourly data (assumes hourly grid; if DST causes 23/25h days, this still works)\n",
    "        train_slice = df.loc[train_start: train_end - pd.Timedelta(hours=1)]\n",
    "        val_slice   = df.loc[val_start:   val_end   - pd.Timedelta(hours=1)]\n",
    "        test_slice  = df.loc[test_start:  test_end  - pd.Timedelta(hours=1)]\n",
    "\n",
    "        # Safety: skip if missing coverage\n",
    "        if train_slice.empty or val_slice.empty or test_slice.empty:\n",
    "            continue\n",
    "\n",
    "        yield SlidingSplit(\n",
    "            forecast_date=D,\n",
    "            train_start=train_start, train_end=train_end,\n",
    "            val_start=val_start, val_end=val_end,\n",
    "            test_start=test_start, test_end=test_end,\n",
    "            X_train=train_slice[feature_cols],\n",
    "            y_train=train_slice[target_col],\n",
    "            X_val=val_slice[feature_cols],\n",
    "            y_val=val_slice[target_col],\n",
    "            X_test=test_slice[feature_cols],\n",
    "            y_test=test_slice[target_col],\n",
    "        )\n",
    "\n",
    "\n",
    "target_col = \"consumption\"\n",
    "feature_cols = [c for c in data.columns if c != target_col]\n",
    "\n",
    "splits = list(iter_sliding_day_ahead_splits(\n",
    "    data,\n",
    "    target_col=target_col,\n",
    "    feature_cols=feature_cols,\n",
    "    last_incomplete_day=\"2023-04-02\",\n",
    "    last_complete_day=\"2023-04-01\",\n",
    "    test_days=14,\n",
    "    history_days=180,\n",
    "    val_days=14,\n",
    "))\n",
    "\n",
    "print(\"Num test days:\", len(splits))\n",
    "print(\"Test window:\", splits[0].forecast_date.date(), \"->\", splits[-1].forecast_date.date())\n",
    "print(\"First split train/val/test:\",\n",
    "      splits[0].train_start.date(), \"->\", (splits[0].train_end - pd.Timedelta(days=0)).date(),\n",
    "      \"|\", splits[0].val_start.date(), \"->\", (splits[0].val_end - pd.Timedelta(days=0)).date(),\n",
    "      \"| test day\", splits[0].forecast_date.date())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
